# æ–‡ä»¶å: server.py
from mcp.server.fastmcp import FastMCP
from dotenv import load_dotenv
import dolphindb as ddb
import sys
import os
import torch
import json

# --- LlamaIndex å¼•ç”¨ ---
from llama_index.core import VectorStoreIndex, Settings, StorageContext
from llama_index.vector_stores.lancedb import LanceDBVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import QueryFusionRetriever

# ==========================================
# 1. å…¨å±€é…ç½® (DolphinDB & LlamaIndex)
# ==========================================
load_dotenv() 

# --- DolphinDB é…ç½® ---
DDB_HOST = os.getenv("DDB_HOST", "127.0.0.1")
DDB_PORT = int(os.getenv("DDB_PORT", 8848))
DDB_USER = os.getenv("DDB_USER", "admin")
DDB_PASS = os.getenv("DDB_PASS", "123456")

# --- MCP Server é…ç½® ---
MCP_SERVER_HOST = os.getenv("MCP_HOST", "0.0.0.0")
MCP_SERVER_PORT = int(os.getenv("MCP_PORT", 8000))
MCP_NAME = "DDB_AI_Agent"

# --- çŸ¥è¯†åº“é…ç½® ---
PERSIST_DIR = os.getenv("PERSIST_DIR", "./storage_data")  # å­˜æ”¾ docstore.json ç­‰
DB_URI = os.getenv("DB_URI", "./lancedb_data")       # å­˜æ”¾å‘é‡æ•°æ®
MODEL_NAME = "BAAI/bge-m3"

# ==========================================
# 2. åˆå§‹åŒ–èµ„æº (å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡ï¼Œé¿å…æ¯æ¬¡æœç´¢éƒ½å¡é¡¿)
# ==========================================
print("ğŸš€ æ­£åœ¨å¯åŠ¨ MCP Server...")

# --- A. åˆå§‹åŒ– DolphinDB è¿æ¥ ---
ddb_session = ddb.session()
try:
    ddb_session.connect(DDB_HOST, DDB_PORT, DDB_USER, DDB_PASS)
    print(f"âœ… DolphinDB connected: {DDB_HOST}:{DDB_PORT}")
except Exception as e:
    print(f"âŒ DolphinDB connection failed: {e}")

# --- B. åˆå§‹åŒ– AI æ£€ç´¢ç³»ç»Ÿ (å®Œå…¨éµå¾ªä½ çš„é€»è¾‘) ---
global_retriever = None 
try:
    print("ğŸ“¥ [1/4] æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹åˆ° GPU...")
    Settings.llm = None
    device_type = "cuda" if torch.cuda.is_available() else "cpu"
    Settings.embedding_model = HuggingFaceEmbedding(
        model_name=MODEL_NAME, 
        device=device_type
    )
    print(f"   æ¨¡å‹åŠ è½½å®Œæˆ (Device: {device_type.upper()})")
    if not os.path.exists(PERSIST_DIR) or not os.path.exists(DB_URI):
        print(f"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°æ•°æ®ç›®å½• ({PERSIST_DIR} æˆ– {DB_URI})ï¼Œæœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
    else:
        print("ğŸ“š [2/4] æ­£åœ¨åŠ è½½ LanceDB å’Œ StorageContext...")
        vector_store = LanceDBVectorStore(uri=DB_URI, table_name="my_vectors")
        
        # ã€å…³é”®ã€‘ä»æŒä¹…åŒ–ç›®å½•åŠ è½½ docstoreï¼Œç¡®ä¿ BM25 æ•°æ®æºå‡†ç¡®
        storage_context = StorageContext.from_defaults(
            persist_dir=PERSIST_DIR, 
            vector_store=vector_store
        )
        
        # åŠ è½½ç´¢å¼•
        index = VectorStoreIndex.from_vector_store(
            vector_store, 
            storage_context=storage_context,
            embed_model=Settings.embedding_model
        )
        
        # å‡†å¤‡å‘é‡æ£€ç´¢å™¨
        vector_retriever = index.as_retriever(similarity_top_k=5)
        print("ğŸ§® [3/4] æ­£åœ¨æ„å»º BM25 ç´¢å¼• (ä» docstore)...")
        # ç›´æ¥ä»åŠ è½½å¥½çš„ docstore è·å–æ‰€æœ‰èŠ‚ç‚¹
        all_nodes = list(storage_context.docstore.docs.values())
        
        if all_nodes:
            bm25_retriever = BM25Retriever.from_defaults(
                nodes=all_nodes, 
                similarity_top_k=5,
                verbose=False
            )
            print("ğŸ”— [4/4] ç»„è£…æ··åˆæ£€ç´¢å™¨ (QueryFusion)...")
            # ã€å…³é”®ã€‘å®Œå…¨éµå¾ªä½ çš„è¦æ±‚ï¼šå»æ‰äº† mode="reciprocal_rank"
            global_retriever = QueryFusionRetriever(
                [vector_retriever, bm25_retriever],
                similarity_top_k=5,
                num_queries=1, 
                # mode="reciprocal_rank",  <-- å·²åˆ é™¤ï¼Œä½¿ç”¨é»˜è®¤å€¼
                use_async=False,
            )
            print("âœ… æ··åˆæ£€ç´¢ç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼")
        else:
            print("âš ï¸ Docstore ä¸ºç©ºï¼Œè·³è¿‡ BM25 æ„å»ºã€‚")
except Exception as e:
    print(f"âŒ AI æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
# ==========================================
# 3. å®šä¹‰ MCP Server ä¸ å·¥å…·
# ==========================================
mcp = FastMCP(
    name=MCP_NAME, 
    host=MCP_SERVER_HOST, 
    port=MCP_SERVER_PORT
)

@mcp.tool()
def execute_ddb_code(code: str) -> str:
    """
    æ‰§è¡Œä¸€æ®µ DolphinDB è„šæœ¬ä»£ç ï¼Œå¹¶è¿”å›ç»“æœã€‚
    ç”¨äºæŸ¥è¯¢æ•°æ®åº“çŠ¶æ€ã€éªŒè¯DolphinDBè¯­æ³•æˆ–è·å–æ•°æ®æ ·æœ¬ã€‚
    """
    print(f"ğŸ“ [DDB] Executing: {code[:50]}...")
    try:
        # 1. å°è¯•ç›´æ¥è¿è¡Œ (DolphinDB SDK ä¼šè‡ªåŠ¨å¤„ç†éƒ¨åˆ†è¿æ¥çŠ¶æ€ï¼Œæˆ–è€…æŠ›å‡ºå¼‚å¸¸)
        result = ddb_session.run(code)
        return str(result)
    except Exception as e:
        # 2. å¦‚æœå¤±è´¥ï¼ˆå¯èƒ½æ˜¯è¿æ¥æ–­å¼€ï¼‰ï¼Œå°è¯•é‡è¿ä¸€æ¬¡
        print(f"âš ï¸ æ‰§è¡Œå¤±è´¥: {e}ã€‚æ­£åœ¨å°è¯•é‡è¿ DolphinDB...")
        try:
            ddb_session.connect(DDB_HOST, DDB_PORT, DDB_USER, DDB_PASS)
            print("âœ… é‡è¿æˆåŠŸï¼Œé‡è¯•æ‰§è¡Œä»£ç ...")
            result = ddb_session.run(code)
            return str(result)
        except Exception as e2:
            # 3. å¦‚æœè¿˜å¤±è´¥ï¼Œé‚£å°±æ˜¯çœŸçš„å¤±è´¥äº†ï¼ˆè¯­æ³•é”™è¯¯æˆ–æ•°æ®åº“æŒ‚äº†ï¼‰
            return f"DolphinDB Error: {str(e2)}"
        
@mcp.tool()
def search_knowledge_base(query: str) -> str:
    """
    æœç´¢æœ¬åœ°çŸ¥è¯†åº“æ–‡æ¡£ã€‚
    å½“ä½ éœ€è¦æŸ¥æ‰¾ DolphinDB çš„ç”¨æ³•ã€é¡¹ç›®æ–‡æ¡£æˆ–æ•™ç¨‹æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    è¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
    """
    print(f"ğŸ” [Search] Query: {query}")
    
    if global_retriever is None:
        return "Error: æ£€ç´¢ç³»ç»Ÿæœªåˆå§‹åŒ– (è¯·æ£€æŸ¥æœåŠ¡å™¨å¯åŠ¨æ—¥å¿—)ã€‚"
    try:
        # æ‰§è¡Œæ£€ç´¢
        results = global_retriever.retrieve(query)
        
        # æ ¼å¼åŒ–ç»“æœ
        output = []
        for node in results:
            output.append({
                "score": round(node.score, 4),
                "file": node.metadata.get("file_name"),
                "content": node.text
            })
        
        return json.dumps(output, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"Search Error: {str(e)}"
# ==========================================
# 4. å¯åŠ¨å…¥å£
# ==========================================
if __name__ == "__main__":
    transport_mode = "streamable-http"
    if len(sys.argv) > 1:
        transport_mode = sys.argv[1]
    print(f"ğŸ“¡ MCP Server Listening on {MCP_SERVER_HOST}:{MCP_SERVER_PORT}")
    mcp.run(transport_mode)
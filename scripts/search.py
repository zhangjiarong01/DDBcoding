import torch
import json
import os
from llama_index.core import (
    StorageContext, 
    VectorStoreIndex, 
    Settings
)
from llama_index.vector_stores.lancedb import LanceDBVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import QueryFusionRetriever

# ================= é…ç½®åŒºåŸŸ =================
device_type = "cuda" if torch.cuda.is_available() else "cpu"

# 1. ç¦ç”¨ LLM (é˜²æ­¢æŠ¥é”™)
Settings.llm = None 

# 2. è®¾ç½® Embedding
Settings.embedding_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-m3", 
    device=device_type
)

PERSIST_DIR = "./storage_data" 
DB_URI = "./lancedb_data"      
# ===========================================

def search(query_text):
    print(f"ğŸ” æ­£åœ¨æœç´¢: {query_text}")

    if not os.path.exists(PERSIST_DIR) or not os.path.exists(DB_URI):
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ ingest.py")
        return []

    vector_store = LanceDBVectorStore(uri=DB_URI, table_name="my_vectors")
    
    try:
        storage_context = StorageContext.from_defaults(
            persist_dir=PERSIST_DIR, 
            vector_store=vector_store
        )
        index = VectorStoreIndex.from_vector_store(
            vector_store, 
            storage_context=storage_context,
            embed_model=Settings.embedding_model
        )
    except Exception as e:
        print(f"âŒ åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
        return []

    # å‡†å¤‡æ£€ç´¢å™¨
    vector_retriever = index.as_retriever(similarity_top_k=5)
    
    all_nodes = list(storage_context.docstore.docs.values())
    if not all_nodes:
        return []

    bm25_retriever = BM25Retriever.from_defaults(
        nodes=all_nodes, 
        similarity_top_k=5,
        verbose=False
    )

    # ==========================================
    # ã€ä¿®å¤ç‚¹ã€‘è¿™é‡Œåˆ é™¤äº† mode="reciprocal_rank"
    # ==========================================
    retriever = QueryFusionRetriever(
        [vector_retriever, bm25_retriever],
        similarity_top_k=5,
        num_queries=1, 
        # mode="reciprocal_rank",  <-- åˆ æ‰è¿™ä¸€è¡Œï¼Œé»˜è®¤å°±æ˜¯ RRF ç®—æ³•
        use_async=False,
    )
    
    results = retriever.retrieve(query_text)
    
    output = []
    for node in results:
        output.append({
            "score": round(node.score, 4),
            "text": node.text, 
            "file_name": node.metadata.get("file_name")
        })
    return output

if __name__ == "__main__":
    import time
    
    query = "mavg" 
    
    start = time.time()
    try:
        res = search(query)
        end = time.time()
        print(f"\nâ±ï¸ è€—æ—¶: {end - start:.4f} ç§’")
        
        if res:
            print(json.dumps(res, indent=2, ensure_ascii=False))
        else:
            print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœã€‚")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
